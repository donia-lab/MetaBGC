#!/usr/bin/env python

#####################################################################################
#@author: francinecamacho
# This file is a component of MetaBGC (Metagenomic identifier of Biosynthetic Gene Clusters)
# (contact Francine Camacho at camachofrancine@gmail.com).
#####################################################################################
from Utils.Utils import RunHMMDirectory
import ntpath
import re
from ExtractFASTASeq import ExtractFASTASeq
from Utils.Utils import PreProcessReads
from Utils.Utils import runTranSeq
from rpy2.robjects.vectors import StrVector
import os
import pandas as pd
import glob
import rpy2.robjects.packages as rpackages
import rpy2.robjects as robjects
from rpy2.robjects import pandas2ri

pandas2ri.activate()

#Filter HMM results using predetermined spHMM models score cutoffs 
def filter_spHMM_data(spHMM_df, cutoff_df):
	filter_spHMM_df = pd.DataFrame()
	for index, row in cutoff_df.iterrows():
		cyclase_model = cutoff_df.at[index,'cyclase_type']
		model_interval = cutoff_df.at[index,'interval']
		cutoff = cutoff_df.at[index,'cutoff']
		#filter spHMM dataframe with designated cutoffs 
		filter_df = spHMM_df.query("HMMScore >= @cutoff & cyclaseType == @cyclase_model & interval == @model_interval").reset_index(drop=True)
		filter_spHMM_df = filter_spHMM_df.append(filter_df)
	return(filter_spHMM_df)

#reformat IDs and filter duplicate readIDs and keep the highest HMM Score 
def create_reformat_data(input_df, outdir):
	base = rpackages.importr('base')
	packageNames = ('tidyverse')
	utils = rpackages.importr('utils')
	utils.chooseCRANmirror(ind=1)
	packnames_to_install = [x for x in packageNames if not rpackages.isinstalled(x)]
	if len(packnames_to_install) > 0:
		utils.install_packages(StrVector(packnames_to_install))
	tidyverse = rpackages.importr('tidyverse')
	robjects.r['options'](warn=-1)
	reformat_df = robjects.r('''
		function(hmmdf,outDir) {
			hmmdfRecoded <- separate(hmmdf, readID, into = c("read","F_R_read_frame"), sep = "_", extra = "merge") %>%
			select(-c(F_R_read_frame))
			hmmdfRecodedDFUnique<-aggregate(HMMScore ~ read + Sample + sampleType + cyclaseType , hmmdfRecoded, max)
			colnames(hmmdfRecodedDFUnique)<-c("readID","Sample", "sampleType", "cyclaseType","HMMScore")
			write_tsv(hmmdfRecodedDFUnique, file.path(outdir, "spHMM-filtered-results.txt"), col_names = T)
		}
		''')
	input_r_df = pandas2ri.py2ri(input_df) # convert pandas df to R datafame

	data_filter = reformat_df(input_r_df,outdir)
	return(data_filter)

def parse_sample_reads(reformat_df, reads_outdir):
	parseReads = robjects.r('''
		function(HMMdf,reads_outdir) {
			samples<-unique(HMMdf$Sample)
			for (s in 1:length(samples)){
				currentSample<-samples[s]
				currentSampleResults<- HMMdf %>% filter(Sample == currentSample)
				currentSampleReads<- unique(currentSampleResults$readID)
				fileName<-paste0(currentSample,paste("-","detected-reads",sep =""), ".txt", sep ="")
				parsedFileName <- file.path(reads_outdir, fileName)
				write.table(currentSampleReads,parsedFileName, quote = F, row.names = F, col.names = F )
		}}
		''')
	parseReads(reformat_df,reads_outdir)

def main(hmm_file, outdir, cutoff_file, fasta_dir):
	spHMM_df = pd.read_csv(hmm_file, sep ="\t", names = ["readID", "sampleType", "Sample", "cyclaseType", "HMMScore", "window","interval"])
	cutoff_df = pd.read_csv(cutoff_file, sep ="\t", header=0)
	spHMM_df_filtered = filter_spHMM_data(spHMM_df, cutoff_df)
	spHMM_df_filtered_reformat = create_reformat_data(spHMM_df_filtered, outdir)
	parse_sample_reads(spHMM_df_filtered_reformat, fasta_dir)

if __name__ == '__main__':
	import argparse
	parser = argparse.ArgumentParser()
	parser.add_argument('--sphmm_directory', required=True, help= "High performance spHMM directory generated by MetaBGC-Build.")
	parser.add_argument('--nucl_seq_directory', required=True, help="Directory with nuleotide fasta files.")
	parser.add_argument('--seq_fmt', required=True, help="Sequence file format and extension.: {fasta,fastq}.")
	parser.add_argument('--pair_fmt', required=True, help="Sequence pair format: {single, split, interleaved}.")
	parser.add_argument('--R1_file_suffix', required=False,
						help="Suffix including extension of the file name specifying R1 reads. Not specified for single or interleaved reads.")
	parser.add_argument('--R2_file_suffix', required=False,
						help="Suffix including extension of the file name specifying R2 reads. Not specified for single or interleaved reads.")
	parser.add_argument('--prot_family_name', required=True, help="Name of the protein family.")
	parser.add_argument('--cohort_name', required=True, help="Name of the sample/cohort name.")
	parser.add_argument('--output_directory', required=True, help="Directory to save results.")
	parser.add_argument('--cpu', required=False, help="Number of threads. Def.: 4")

	args = parser.parse_args()

	if args.cpu is not None:
		CPU_THREADS = args.cpu

	nucl_seq_directory = PreProcessReads(args.nucl_seq_directory, args.seq_fmt, args.pair_fmt,
										 args.R1_file_suffix.strip(), args.R2_file_suffix.strip(),
										 args.output_directory)

	# Translate nucleotide seq
	prot_seq_directory = os.path.join(args.output_directory, 'prot_identify_seq_dir')
	os.makedirs(prot_seq_directory, 0o777, True)
	for subdir, dirs, files in os.walk(nucl_seq_directory):
		for file in files:
			filePath = os.path.join(subdir, file)
			if re.match(r".*\.fasta$", file) and os.path.getsize(filePath) > 0:
				prot_file = prot_seq_directory + os.sep + ntpath.basename(filePath)
				runTranSeq(filePath, "6", prot_file)

	# HMMER search
	hmm_search_directory = os.path.join(args.output_directory, 'hmm_identify_search')
	os.makedirs(hmm_search_directory, 0o777, True)
	for filename in os.listdir(args.hmm_directory):
		fileBase = ntpath.basename(filename)
		hmmInterval = fileBase.split("__")[2]
		if filename.endswith(".hmm"):
			RunHMMDirectory(prot_seq_directory, filename, args.cohort_name, args.prot_family_name, "30_10", hmmInterval,
						hmm_search_directory, CPU_THREADS)

	allHMMResult = hmm_search_directory + os.sep + "CombinedHmmSearch.txt"
	with open(allHMMResult, 'w') as outfile:
		for subdir, dirs, files in os.walk(hmm_search_directory):
			for file in files:
				filePath = os.path.join(subdir, file)
				if re.match(r".*txt$", file) and os.path.getsize(filePath) > 0:
					with open(filePath) as infile:
						for line in infile:
							outfile.write(line)

	identify_directory = os.path.join(args.output_directory, 'identify_result')
	os.makedirs(identify_directory, 0o777, True)
	fasta_dir = os.path.join(args.output_directory, 'fasta_result')
	os.makedirs(fasta_dir, 0o777, True)
	cutoff_file = os.path.join(args.hmm_directory, args.prot_family_name + "_F1_Cutoff.txt")
	main(allHMMResult, identify_directory, cutoff_file, fasta_dir)

	allHMMResult = fasta_dir + os.sep + "CombinedReadIds.txt"
	with open(allHMMResult, 'w') as outfile:
		for filename in os.listdir(fasta_dir):
			if filename.endswith(".txt"):
				with open(filename) as infile:
					for line in infile:
						outfile.write(line)

	multiFastaFile = args.output_directory + os.sep + "identified-biosynthetic-reads.fasta"
	ExtractFASTASeq(nucl_seq_directory,multiFastaFile,allHMMResult)

